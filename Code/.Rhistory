requiredPackages = c("data.table", "cvTools", "ggplot2", "corrplot", "DMwR", "caret",  "Hmisc", "randomForest", "gmodels", "outliers")
requirePackage <- function(x)
{
if (!require(x,character.only = TRUE, warn.conflicts = FALSE))
{
install.packages(x,dep=TRUE)
if(!require(x,character.only = TRUE)) stop("Package not found")
}
}
for (package in requiredPackages) {
requirePackage(package)
}
dir <- Sys.getenv('BADS_Path')
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
print("tesfhsd")
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
#Load Data
source(paste0(dir, "/Code/DataLoader.R"))
trainingset = getTrainigset(dir)
#Exploratory Data Analysis
#churn =1
subsetData_churn_true<-trainingset[trainingset$churn==1,]
#churn = 0
subsetData_churn_false<-trainingset[trainingset$churn==0,]
hist(trainingset$adults, main = "Number of Adults")
hist(trainingset$age1, col="blue", main = "Age first household member")
hist(trainingset$age2, col="red", add=TRUE)
legend("topright", c("First Household Member","Second Household Member"),lty=c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
#plots hists of all 138 numeric variables
#plotHists(numericVariables, 5)
##Missing Value Handling
source(paste0(dir,"/Code/missingValueHandler.R"))
numericCompleteCases <- getImputedData(numericVariables)
categoricCompleteCases <- getImputedData(categoricVariables)
completeCases <- getImputedData(trainingset)
getAccuracy <- function(model, testSet){
pred <- predict(model, newdata=testSet, type="response")
class <- round(pred)
confustionTable <- CrossTable(testSet$churn, class, prop.c=FALSE)$t
return((confustionTable[1,1]+confustionTable[1,2])/length(y))
}
n <- 10
dataset = completeCases[1:50000,]
setSize = round(dim(dataset)[1]/n)
shuffledDataset <- dataset[sample(nrow(dataset)),]
avg=0
for (i in 1:n) {
print(i)
inds.test = ((i-1)*setSize+1):((i-1)*setSize+setSize)
inds.training = setdiff(1:nrow(dataset), inds.test)
test = shuffledDataset[inds.test,]
training = shuffledDataset[inds.training,]
lr<-glm(churn~.,data=training,family=binomial(link="logit"))
avg = avg + getAccuracy(model = lr, testSet = test)
}
#rf <- randomForest(churn~.,data=completeCases[1:1000,],ntree=500, mtry=3)
res = round(predict(rf, newdata = completeCases[1001:2000,]))
y = completeCases[1001:2000,]
CrossTable(y$churn, res, prop.c=FALSE)$t
#identify highly corelated coplete veriables (only numeric)
correlationMatrix <- cor(completeCases[,])
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
#verbose=TRUE
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# print indexes of highly correlated attributes
print(highlyCorrelated)
head(completeCases[,highlyCorrelated])
#delete highly corelated columns
cleanedDataCoplete<-completeCases[,-highlyCorrelated]
#remove highly corelated from the original data
colunmNames<-colnames(completeCases)[highlyCorrelated]
cleanedOriginalData<-trainingset[,!(names(trainingset) %in% colunmNames)]
install.packages("HighDimOut")
library(HighDimOut)
test<-cleanedDataCoplete[1:100,1:37]
tim2<- Func.FBOD(test, iter=10, k.nn=37) # cannot allocate a vector of 3.5 Gb
plot(tim2)
show.outlier<-tim2[tim2>=2] # TRUE/FALSE Vector which shows all the outliers (value 2 is manuel, lets discuss this)
show.outlier
View(cleanedDataCoplete)
dir <- Sys.getenv('BADS_Path')
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
print("tesfhsd")
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
#Load Data
source(paste0(dir, "/Code/DataLoader.R"))
trainingset = getTrainigset(dir)
#Exploratory Data Analysis
#churn =1
subsetData_churn_true<-trainingset[trainingset$churn==1,]
#churn = 0
subsetData_churn_false<-trainingset[trainingset$churn==0,]
hist(trainingset$adults, main = "Number of Adults")
hist(trainingset$age1, col="blue", main = "Age first household member")
hist(trainingset$age2, col="red", add=TRUE)
legend("topright", c("First Household Member","Second Household Member"),lty=c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
#plots hists of all 138 numeric variables
#plotHists(numericVariables, 5)
##Missing Value Handling
source(paste0(dir,"/Code/missingValueHandler.R"))
numericCompleteCases <- getImputedData(numericVariables)
categoricCompleteCases <- getImputedData(categoricVariables)
completeCases <- getImputedData(trainingset)
#completeInds <- complete.cases(t(numericVariables))
#completeCases = numericVariables[completeInds]
dir <- Sys.getenv('BADS_Path')
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
print("tesfhsd")
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
#Load Data
source(paste0(dir, "/Code/DataLoader.R"))
trainingset = getTrainigset(dir)
#Exploratory Data Analysis
#churn =1
subsetData_churn_true<-trainingset[trainingset$churn==1,]
#churn = 0
subsetData_churn_false<-trainingset[trainingset$churn==0,]
hist(trainingset$adults, main = "Number of Adults")
hist(trainingset$age1, col="blue", main = "Age first household member")
hist(trainingset$age2, col="red", add=TRUE)
legend("topright", c("First Household Member","Second Household Member"),lty=c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
#plots hists of all 138 numeric variables
#plotHists(numericVariables, 5)
##Missing Value Handling
source(paste0(dir,"/Code/missingValueHandler.R"))
numericCompleteCases <- getImputedData(numericVariables)
categoricCompleteCases <- getImputedData(categoricVariables)
completeCases <- getImputedData(trainingset)
#completeInds <- complete.cases(t(numericVariables))
#completeCases = numericVariables[completeInds]
getAccuracy <- function(model, testSet){
pred <- predict(model, newdata=testSet, type="response")
class <- round(pred)
confustionTable <- CrossTable(testSet$churn, class, prop.c=FALSE)$t
return((confustionTable[1,1]+confustionTable[1,2])/length(y))
}
n <- 10
dataset = completeCases[1:50000,]
setSize = round(dim(dataset)[1]/n)
shuffledDataset <- dataset[sample(nrow(dataset)),]
avg=0
for (i in 1:n) {
print(i)
inds.test = ((i-1)*setSize+1):((i-1)*setSize+setSize)
inds.training = setdiff(1:nrow(dataset), inds.test)
test = shuffledDataset[inds.test,]
training = shuffledDataset[inds.training,]
lr<-glm(churn~.,data=training,family=binomial(link="logit"))
avg = avg + getAccuracy(model = lr, testSet = test)
}
#rf <- randomForest(churn~.,data=completeCases[1:1000,],ntree=500, mtry=3)
res = round(predict(rf, newdata = completeCases[1001:2000,]))
y = completeCases[1001:2000,]
CrossTable(y$churn, res, prop.c=FALSE)$t
#Corelation
#identify highly corelated coplete veriables (only numeric)
correlationMatrix <- cor(completeCases[,])
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
#verbose=TRUE
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# print indexes of highly correlated attributes
print(highlyCorrelated)
head(completeCases[,highlyCorrelated])
#delete highly corelated columns
cleanedDataCoplete<-completeCases[,-highlyCorrelated]
#remove highly corelated from the original data
colunmNames<-colnames(completeCases)[highlyCorrelated]
cleanedOriginalData<-trainingset[,!(names(trainingset) %in% colunmNames)]
##############################################################################################
#high dimensional data
#install.packages("HighDimOut")
#library(HighDimOut)
#test<-cleanedDataCoplete[1:20,1:25]
#tim1<-Func.ABOD(test,basic=FALSE, .9)
#braucht bei mir ewig fÃ¼r 0.01 prozent im 3D SPACE mit allen Obs (nach 1h noch kein Ergebnis)
#angle-based outlier detection (ABOD) algorithm, calculates the outlier due to there angel base
#small value = outlier
#high value = no outlier;explanation on the LMU slides
#plot(tim1)
#max(tim1)
#########################################################################
install.packages("HighDimOut")
library(HighDimOut)
test<-cleanedDataCoplete[1:100,1:37]
tim2<- Func.FBOD(test, iter=10, k.nn=37) # cannot allocate a vector of 3.5 Gb
#tim is calculated with LOF
# value <<1 the point is in the cluster; value >> the point is far away from cluster
plot(tim2)
dir <- Sys.getenv('BADS_Path')
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
print("tesfhsd")
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
source(paste0(dir, "/Code/DataLoader.R"))
trainingset = getTrainigset(dir)
subsetData_churn_true<-trainingset[trainingset$churn==1,]
#churn = 0
subsetData_churn_false<-trainingset[trainingset$churn==0,]
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
source(paste0(dir,"/Code/missingValueHandler.R"))
numericCompleteCases <- getImputedData(numericVariables)
completeCases <- getImputedData(trainingset)
K <- getOutliers(completeCases$blck_vce_Mean, method="I")
outlierPlot(completeCases$blck_vce_Mean,K,mode="qq")
install.packages("extremevalues")
library("extremevalues")
boxplot(completeCases$blck_vce_Mean)
hist(trainingset$adults, main = "Number of Adults")
hist(completeCases$blck_vce_Mean)
K <- getOutliers(completeCases$blck_vce_Mean, method="I")
outlierPlot(completeCases$blck_vce_Mean,K,mode="qq")
K
?getOutliers
K <- getOutliers(completeCases$blck_vce_Mean, method="I", rho=c(0.01,0.01))
K
dir <- Sys.getenv('BADS_Path')
dir<-getwd()
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
#Load Data
source(paste0(dir, "/Code/DataLoader.R"))
trainingset = getTrainigset(dir)
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
#Exploratory Data Analysis
source(paste0(dir, "/Code/ExploratoryDataAnalysis.R"))
createUsefulPlots(trainingset, numericVariables, categoricVariables)
dir <- Sys.getenv('BADS_Path')
dir<-getwd()
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
dir <- Sys.getenv('BADS_Path')
#dir<-getwd()
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
#Load Data
source(paste0(dir, "/Code/DataLoader.R"))
trainingset = getTrainigset(dir)
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
#Exploratory Data Analysis
source(paste0(dir, "/Code/ExploratoryDataAnalysis.R"))
createUsefulPlots(trainingset, numericVariables, categoricVariables)
#rf <- randomForest(churn~.,data=completeCases[1:1000,],ntree=500, mtry=3)
res = round(predict(rf, newdata = completeCases[1001:2000,]))
y = completeCases[1001:2000,]
CrossTable(y$churn, res, prop.c=FALSE)$t
##Missing Value Handling
source(paste0(dir,"/Code/missingValueHandler.R"))
numericCompleteCases <- getImputedData(numericVariables)
categoricCompleteCases <- getImputedData(categoricVariables)
completeCases <- getImputedData(trainingset)
source(paste0(dir, "/Code/ModelTrainer.R"))
n <- 10
dataset = completeCases[1:50000,]
setSize = round(dim(dataset)[1]/n)
shuffledDataset <- dataset[sample(nrow(dataset)),]
avg=0
for (i in 1:n) {
print(i)
inds.test = ((i-1)*setSize+1):((i-1)*setSize+setSize)
inds.training = setdiff(1:nrow(dataset), inds.test)
test = shuffledDataset[inds.test,]
training = shuffledDataset[inds.training,]
lr<-glm(churn~.,data=training,family=binomial(link="logit"))
avg = avg + getAccuracy(model = lr, testSet = test)
}
#rf <- randomForest(churn~.,data=completeCases[1:1000,],ntree=500, mtry=3)
res = round(predict(rf, newdata = completeCases[1001:2000,]))
y = completeCases[1001:2000,]
CrossTable(y$churn, res, prop.c=FALSE)$t
correlationMatrix <- cor(completeCases[,])
print(correlationMatrix)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# print indexes of highly correlated attributes
print(highlyCorrelated)
head(completeCases[,highlyCorrelated])
#delete highly corelated columns
cleanedDataCoplete<-completeCases[,-highlyCorrelated]
colunmNames<-colnames(completeCases)[highlyCorrelated]
cleanedOriginalData<-trainingset[,!(names(trainingset) %in% colunmNames)]
#find variables which must contain outliers
difference.Median.Median<-abs(apply(completeCases,2, function(x) median(x)-mean(x)))
#st.d<-apply(completeCases,2,sd)
indicies <- which(difference.Median.Median>apply(completeCases,2,median)/2)
summary(completeCases[,indicies])
source(paste0(dir, "/Code/Outliers.R"))
#replace outliers with means for variables
boxplot(completeCases[1:2])
variable<-handle.Outliers.for.Matrix(completeCases[,1:(length(completeCases-2))], 1.5)
colnames(variable)
data.without.outliers<-apply(dataset,2, function(x) x<-variable[, colnames(x) ])
numericVariables
difference.Median.Median<-abs(apply(completeCases,2, function(x) median(x)-mean(x)))
#st.d<-apply(completeCases,2,sd)
indicies <- which(difference.Median.Median>apply(completeCases,2,median)/2)
summary(completeCases[,indicies])
summary(trainingset[,50:78])
?nnet
?glmnet
getSelectedFeatureSet <- function(dir){
data <- read.csv(paste0(dir, "/data/feature_selection_variablenames.csv",header=TRUE, sep = ";"))
return(data)
}
selectedFeatures <- getSelectedFeatureSet(dir)
View(getSelectedFeatureSet)
getContinousset <- function(dir){
data <- read.csv(paste0(dir, "/data/continous_variablenames.csv",header=TRUE, sep = ";"))
return(data)
}
continousVariablesname <- getContinousset(dir)
getTrainigset <- function(dir){
data <- read.csv(paste0(dir, "/data/trainingset.csv"), sep = ',')
return(data)
}
trainingset = getTrainigset(dir)
dir <- Sys.getenv('BADS_Path')
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
continousVariablesname <- getContinousset(dir)
source(paste0(dir, "/Code/DataLoader.R"))
trainingset = getTrainigset(dir)
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
continousVariablesname <- getContinousset(dir)
selectedFeatures <- getSelectedFeatureSet(dir)
dir <- Sys.getenv('BADS_Path')
setwd("~/Documents/HU Berlin/WI 1516/BADS/Aufgabe/BADS")
#dir<-getwd()
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
#Load Data
source(paste0(dir, "/Code/DataLoader.R"))
trainingset = getTrainigset(dir)
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
continousVariablesname <- getContinousset(dir)
#Exploratory Data Analysis
source(paste0(dir, "/Code/ExploratoryDataAnalysis.R"))
#createUsefulPlots(trainingset, numericVariables, categoricVariables)
print("Loaded Dataset")
##Missing Value Handling
source(paste0(dir,"/Code/missingValueHandler.R"))
#trainingset <- getImputedData(trainingset)
#numericVariables = getNumericVariables(trainingset)
#categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(trainingset))]
#write.csv(trainingset, paste0(dir, "/Data/ImputedData.csv"), sep = ",")
trainingset <- loadImputedTrainingset(paste0(dir, "/Data/ImputedData.csv"))
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
print("Finished Missing Value Handling")
names(numericVariables)
View(numericVariables)
getSelectedFeatureSet <- function(dir){
data <- read.csv(paste0(dir, "/Data/feature_selection_variablenames.csv"),header=TRUE, sep = ";")
return(data)
}
selectedFeatures <- getSelectedFeatureSet(dir)
selectedFeatures <- c(as.vector(selectedFeatures[,1]), "churn")
selectedFeatures
categoricVariables
names(categoricVariables)
